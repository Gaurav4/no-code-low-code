{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from time import gmtime, strftime\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "import boto3\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = 'loan-default-prediction'\n",
    "region = 'us-east-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_input = f's3://{bucket}/{prefix}/batch_input/'\n",
    "batch_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_output = f's3://{bucket}/{prefix}/batch_output/'\n",
    "batch_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_timestamp = strftime('%Y-%m-%d-%H-%M-%S', gmtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_job_name = 'predict-loan-default'  # Copy this from the console\n",
    "model_name = f'autopilot-best-model-{current_timestamp}'\n",
    "transform_job_name = f'autopilot-batch-job-{current_timestamp}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session()\n",
    "sagemaker_execution_role = get_execution_role()\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "sagemaker_client = boto3.client('sagemaker', region_name=region)\n",
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy batch input data from local to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp ./data/train/loans_unlabeled.csv {batch_input}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the best model using Autopilot job name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_candidate = sagemaker_client.describe_auto_ml_job(AutoMLJobName=automl_job_name)[\"BestCandidate\"]\n",
    "best_candidate_name = best_candidate[\"CandidateName\"]\n",
    "print(f\"CandidateName: {best_candidate_name}\")\n",
    "print(f'FinalAutoMLJobObjectiveMetricName: {best_candidate[\"FinalAutoMLJobObjectiveMetric\"][\"MetricName\"]}')\n",
    "print(f'FinalAutoMLJobObjectiveMetricValue: {best_candidate[\"FinalAutoMLJobObjectiveMetric\"][\"Value\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sagemaker_client.create_model(Containers=best_candidate[\"InferenceContainers\"], \n",
    "                                      ModelName=model_name, \n",
    "                                      ExecutionRoleArn=sagemaker_execution_role)\n",
    "\n",
    "print(f'Model ARN corresponding to the best candidate is : {model[\"ModelArn\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Batch Transform job "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_input = {\n",
    "    \"DataSource\": {\"S3DataSource\": {\"S3DataType\": \"S3Prefix\", \"S3Uri\": batch_input}},\n",
    "    \"ContentType\": \"text/csv\",\n",
    "    \"CompressionType\": \"None\",\n",
    "    \"SplitType\": \"Line\",\n",
    "}\n",
    "\n",
    "transform_output = {\n",
    "    \"S3OutputPath\": batch_output,\n",
    "}\n",
    "\n",
    "transform_resources = {\"InstanceType\": \"ml.m5.4xlarge\", \"InstanceCount\": 1}\n",
    "\n",
    "sagemaker_client.create_transform_job(\n",
    "    TransformJobName=transform_job_name,\n",
    "    ModelName=model_name,\n",
    "    TransformInput=transform_input,\n",
    "    TransformOutput=transform_output,\n",
    "    TransformResources=transform_resources,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the status of the running job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[JobStatus]\\n\")\n",
    "\n",
    "\n",
    "describe_response = sagemaker_client.describe_transform_job(TransformJobName=transform_job_name)\n",
    "job_run_status = describe_response[\"TransformJobStatus\"]\n",
    "print(job_run_status)\n",
    "\n",
    "while job_run_status not in (\"Failed\", \"Completed\", \"Stopped\"):\n",
    "    describe_response = sagemaker_client.describe_transform_job(TransformJobName=transform_job_name)\n",
    "    job_run_status = describe_response[\"TransformJobStatus\"]\n",
    "    print(job_run_status)\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the output of the batch transform job from S3 to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_key = f\"{prefix}/batch_output/loans_unlabeled.csv.out\"\n",
    "local_inference_results_path = \"./data/train/inference_results.csv\"\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "\n",
    "\n",
    "inference_results_bucket = s3.Bucket(sagemaker_session.default_bucket())\n",
    "\n",
    "inference_results_bucket.download_file(s3_output_key, local_inference_results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(local_inference_results_path, sep=\";\")\n",
    "pd.set_option(\"display.max_rows\", 10)  \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
